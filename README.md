# Экзамен по инжинирингу данных. 2 семестр  

**Тема:** Автоматизация и оркестрация пайплайна машинного обучения с использованием Apache Airflow  

**ML-задача:** Бинарная классификация опухолей молочной железы (злокачественные/Malignant или доброкачественные/Benign) на основе характеристик клеточных ядер. (LogisticRegression)  

### Содержание проекта:  
- Структура файлов проекта  
- Этап 1. Планирование пайплайна  
- Этап 2. Разработка ETL-компонентов  
- Этап 3. Оркестрация пайплайна с помощью Airflow  
- Этап 4. Интеграция с локальным диском  
- Этап 5. Анализ ошибок и устойчивости  
- Дополнительные файлы  

### Структура файлов проекта:  
```plaintext
project/                                         
├── config/                                      # Папка файлов конфигурации
│   ├── __init__.py                              # Делает конфигурационные параметры доступными через короткий импорт
│   └── config.py                                # Файл с указанием путей проекта
│
├── dags/                                        # Папка DAGs проекта
│   └── pipeline_dag.py                          # Основной файл DAG пайплайна проекта
│
├── data/                                        # Данные проекта
│   ├── processed/                               # Готовые наборы данных для обучения и тестирования
│   │   ├── X_test.csv                           # Признаки для тестирования
│   │   ├── X_train.csv                          # Признаки для обучения
│   │   ├── y_test.csv                           # Истинные значения для тестирования
│   │   └── y_train.csv                          # Целевая переменная для обучения
│   │
│   └── breast_cancer_wisconsin_diagnostic.csv   # Исходный файл с данными
│
├── etl/                                         # Скрипты etl-процесса
│   ├── __init__.py                              # Oбъявляет директорию с ETL-скриптами как Python-пакет
│   ├── load_data.py                             # Скрипт загрузки первичных данных
│   ├── preprocess_data.py                       # Скрипт предобработки данных
│   ├── train_model.py                           # Скрипт обучения модели 
│   └── evaluate_model.py                        # Скрипт оценки модели
│
├── results/                                     # Итоговые артефакты проекта
│   ├── model.pkl                                # Файл с сериализованной обученной моделью логистической регрессии
│   └── metrics.json                             # Файл с метриками качества модели
│
├── logs/                                        # Папка с логами выполнения DAG
│
├── requirements.txt                             # Зависимости проекта
└── README.md                                    # Описание проекта
```

### Этап 1. Планирование пайплайна  

Общая схема пайплайна содержит 5 последовательных шага, которые представлены на схеме:
<p align="center">
<img  src="https://github.com/LeshchenkoB/DE_exam/blob/main/Схема%20пайплайна.png"  width="175" alt="Pipline"/>
</p>

На шаге **загрузка данных** производится первичная загрузка исходных сырых данных.  
На шаге **предобработка** разделение признаков и целевой переменной, нормализация признаков с помощью StandardScaler, а также разделение на обучающую и тестовую выборки.  
На шаге **обучение модели** строится предсказательная модель на основе подготовленных данных.  
На шаге **оценка метрик** выполняется оценка обученной модели на тестовых данных: предсказываются метки, вычисляется Accuracy, Precision, Recall и F1-score.  
На шаге **сохранение результатов** выполняется запись полученных метрики в локальные файлы в папку result.

### Этап 2. Разработка ETL-компонентов
Шаги пайплайна связаны со скриптами, обеспечивающими ETL-процесс следующим образом:  
- *загрузка данных* -> **load_data.py** - загружает первичные данные, создаем признак *target* и сохраняет файл в breast_cancer_wisconsin_diagnostic.csv  
- *предобработка* -> **preprocess_data.py** - Осуществляет предобработку данных: разделение признаков и целевой переменной, нормализацию признаков с помощью StandardScaler, а также разделение на обучающую и тестовую выборки (train_test_split).
Готовит данные к обучению модели.  
- *обучение модели* -> **train_model.py** - Обучает модель логистической регрессии (LogisticRegression) на обучающих данных. Сохраняет обученную модель с помощью pickle в заданный путь. На этом шаге строится предсказательная модель на основе подготовленных данных.
- *оценка метрик* и *сохранение результатов* -> **evaluate_model.py** - Выполняет оценку обученной модели на тестовых данных: предсказывает метки, вычисляет Accuracy, Precision, Recall и F1-score. Сохраняет полученные метрики в JSON-файл. Это важно для анализа качества модели и дальнейшего сравнения.

### Этап 3. Оркестрация пайплайна с помощью Airflow  
Правила и последовательность выполнения скриптов реализованы с помощью DAG *breast_cancer_ml_pipeline*, скрипт которого содержится в файле **pipline_dag.py**

В DAG реализована последовательное выполнение скриптов ETL, без какого-либо параллеливания, т.к. это не предполагается логикой самого процесса, который должен выполняться последовательно и каждый последующий шаг использует результаты предыдущего.  

В файле самого скрипта такая последовательность реализована через указание:  
```task_load_data >> task_preprocess >> task_train >> task_evaluate```  

Так же настроено расписание запуска DAG (значение аргумента schedule_interval), ежедневно в 8 часов.  

***Для того, чтобы запустить все скрипты проекта***, необходимо выполнить следующие действия:  
- создать структуру папок, как указана в описании *структура файлов проекта* и сохранить в них все файлы с расширением **.py** так же в соответствии с описанием структуры;  
- при необходимости указать актуальные пути к файлам для переменных в файле **config.py**
- запустить DAG. Для этого можно воспользоваться web-интерфейсом Airflow, или выполнить следующую команду: ```airflow dags trigger breast_cancer_ml_pipeline```

### Этап 4. Интеграция с локальным диском
Логика реализации проекта предполагает локальное хранение результатов работы (исходных данных, промежуточных/вспомогательных файлов, файлов модели и метрик). 
Исходные данные храняться в папке **data**.
Предобработанные данные хранятся внутри папки data в подпапке **processed**.  
Результаты работы (файл модели и метрики) хранятся в папке **result**.  
Все пути к файлам внутри папок задаются в конфигурационном файле **config.py**, а в самих скриптах используется указание на переменные этого файла, для использования необходимого пути. Таким образом, для того, чтобы воспроизвести реализацию данного проекта на стороне пользователя достаточно в файле **config.py** указать корректные пути к необходимым папкам и запустить DAG.

### Этап 5. Анализ ошибок и устойчивости

В процессе эксплуатации могут возникнуть следующие **проблемы и ошибки**:
- Загрузка данных:  
*Ошибка*: Файл недоступен
*Обработка:* retries=3, проверка структуры

- Предобработка:  
*Ошибка:* Невалидные значения
*Обработка:* try/except, логирование

- Обучение модели:
*Ошибка:* NaN в данных
*Обработка:* проверка данных перед обучением

**Механизмы устойчивости:**  
- *Логирование на каждом шаге:* данный шаг реализован в коде каждого отдельного скрипта.  
- *Автоматические повторы (retries):* данный шаг реализован в коде DAG.  
- *Изоляция задач (каждый шаг независим):* данный шаг не применим в контексте текущей задачи, но может быть учтен при необходимости и возможности.  
- *Валидация данных на входе/выходе:* данные процедуры реализованы в коде.  
- *Отправка уведомлений на почту в случае сбоя выполнения DAG:* данный шаг является примером дальнейшего улучшения и развития проекта.(**идея для развития проекта**)

### Справочно:
Скрин выполнения DAG:
<p align="center">
<img  src="https://github.com/LeshchenkoB/DE_exam/blob/main/Скрин%20выполнения%20DAG.PNG"  width="960" alt="Pipline"/>
</p>
